{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN0kaxMdGGXh",
        "outputId": "6bbe75f9-a202-4dd6-f962-c51c48653d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ì•™ìƒë¸” ëª¨ë¸ (RF + XGBoost + FT Transformer)\n",
        "# =============================================================================\n",
        "\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
        "!pip install optuna -q\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SghSPZP_Vnzm",
        "outputId": "aed84a55-cd98-46b7-b53a-8a21f64a9b90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ë°ì´í„° ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "jU-X-rNiVhmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. ë°ì´í„° ë¡œë“œ"
      ],
      "metadata": {
        "id": "x_pAfol1VvbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/preprocessed_data.pkl'\n",
        "\n",
        "with open(DATA_PATH, 'rb') as f:\n",
        "    data_dict = pickle.load(f)\n",
        "\n",
        "X_test = data_dict['X_test_clf']\n",
        "y_test = data_dict['y_test_clf']\n",
        "\n",
        "print(f\"âœ… Test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwkkWm_NVz33",
        "outputId": "4069ce37-92b3-4b0d-fbb9-939209594efd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ“‚ ë°ì´í„° ë¡œë“œ\n",
            "============================================================\n",
            "âœ… Test: (9670, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. RandomForest ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "D5tPAj_HVwva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(df):\n",
        "    data = df.copy()\n",
        "\n",
        "    if 'outstanding_debt' in data.columns and 'annual_income' in data.columns:\n",
        "        data['debt_to_income'] = data['outstanding_debt'] / (data['annual_income'] + 1)\n",
        "    if 'total_emi_per_month' in data.columns and 'monthly_inhand_salary' in data.columns:\n",
        "        data['emi_to_income'] = data['total_emi_per_month'] / (data['monthly_inhand_salary'] + 1)\n",
        "    if 'monthly_balance' in data.columns and 'monthly_inhand_salary' in data.columns:\n",
        "        data['balance_to_income'] = data['monthly_balance'] / (data['monthly_inhand_salary'] + 1)\n",
        "    if 'amount_invested_monthly' in data.columns and 'monthly_inhand_salary' in data.columns:\n",
        "        data['invest_to_income'] = data['amount_invested_monthly'] / (data['monthly_inhand_salary'] + 1)\n",
        "    if 'num_credit_card' in data.columns and 'credit_utilization_ratio' in data.columns:\n",
        "        data['credit_load'] = data['num_credit_card'] * data['credit_utilization_ratio']\n",
        "    if 'delay_from_due_date' in data.columns and 'num_of_delayed_payment' in data.columns:\n",
        "        data['delay_severity'] = data['delay_from_due_date'] * data['num_of_delayed_payment']\n",
        "    if 'num_of_loan' in data.columns and 'num_bank_accounts' in data.columns:\n",
        "        data['loan_per_account'] = data['num_of_loan'] / (data['num_bank_accounts'] + 1)\n",
        "    if 'num_credit_inquiries' in data.columns and 'credit_history_age' in data.columns:\n",
        "        data['inquiries_per_year'] = data['num_credit_inquiries'] / (data['credit_history_age'] / 12 + 1)\n",
        "    if 'num_bank_accounts' in data.columns and 'credit_history_age' in data.columns:\n",
        "        data['accounts_per_year'] = data['num_bank_accounts'] / (data['credit_history_age'] / 12 + 1)\n",
        "    if 'total_emi_per_month' in data.columns and 'outstanding_debt' in data.columns and 'interest_rate' in data.columns:\n",
        "        data['payment_burden'] = data['total_emi_per_month'] + data['outstanding_debt'] * (data['interest_rate'] / 100)\n",
        "    if 'annual_income' in data.columns:\n",
        "        data['log_income'] = np.log1p(data['annual_income'])\n",
        "    if 'outstanding_debt' in data.columns:\n",
        "        data['log_debt'] = np.log1p(data['outstanding_debt'])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "N2bKxCWIV4HX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RandomForest"
      ],
      "metadata": {
        "id": "9fKwQg1BHS7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Random Forest ë¡œë“œ\n",
        "RF_PATH = '/content/drive/MyDrive/best_rf_model.pkl'\n",
        "with open(RF_PATH, 'rb') as f:\n",
        "    rf_dict = pickle.load(f)\n",
        "rf_model = rf_dict['model']\n",
        "rf_top_features = rf_dict['top_features']\n",
        "print(f\"âœ… RF ë¡œë“œ ì™„ë£Œ (í”¼ì²˜: {len(rf_top_features)}ê°œ)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBK7iuhfV_2J",
        "outputId": "b8078ef2-3343-44e3-9a05-d0da8a58f3d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RF ë¡œë“œ ì™„ë£Œ (í”¼ì²˜: 20ê°œ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. XGBoost"
      ],
      "metadata": {
        "id": "waAFSFLwHVXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. XGBoost ë¡œë“œ\n",
        "XGB_PATH = '/content/drive/MyDrive/best_xgb_model.pkl'\n",
        "with open(XGB_PATH, 'rb') as f:\n",
        "    xgb_dict = pickle.load(f)\n",
        "xgb_model = xgb_dict['model']\n",
        "print(f\"âœ… XGBoost ë¡œë“œ ì™„ë£Œ (ì›ë³¸ í”¼ì²˜)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyLaCEhKWHCv",
        "outputId": "e30c0ffc-f563-4669-9536-fcf4b6b67114"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… XGBoost ë¡œë“œ ì™„ë£Œ (ì›ë³¸ í”¼ì²˜)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. FT Transformer"
      ],
      "metadata": {
        "id": "Az_8mr7AHXvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. FT Transformer ë¡œë“œ\n",
        "FT_PATH = '/content/drive/MyDrive/best_ft_model.pkl'\n",
        "with open(FT_PATH, 'rb') as f:\n",
        "    ft_dict = pickle.load(f)\n",
        "\n",
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, embed_dim=64, num_heads=4,\n",
        "                 num_layers=3, ff_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.feature_embedding = nn.Linear(1, embed_dim)\n",
        "        self.input_dim = input_dim\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, input_dim + 1, embed_dim))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(ff_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.feature_embedding(x)\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        x = x + self.pos_embedding\n",
        "        x = self.transformer(x)\n",
        "        cls_output = x[:, 0]\n",
        "        cls_output = self.norm(cls_output)\n",
        "        return self.fc(cls_output)\n",
        "\n",
        "ft_params = ft_dict['best_params']\n",
        "ft_model = FTTransformer(\n",
        "    input_dim=ft_dict['input_dim'],\n",
        "    num_classes=3,\n",
        "    embed_dim=ft_params['embed_dim'],\n",
        "    num_heads=ft_params['num_heads'],\n",
        "    num_layers=ft_params['num_layers'],\n",
        "    ff_dim=ft_params['ff_dim'],\n",
        "    dropout=ft_params['dropout']\n",
        ").to(device)\n",
        "ft_model.load_state_dict(ft_dict['model_state'])\n",
        "ft_model.eval()\n",
        "ft_scaler = ft_dict['scaler']\n",
        "print(f\"âœ… FT Transformer ë¡œë“œ ì™„ë£Œ (ì›ë³¸ í”¼ì²˜)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8hY0G00WEhs",
        "outputId": "042514a9-a8d7-469b-d622-c76510e8e747"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FT Transformer ë¡œë“œ ì™„ë£Œ (ì›ë³¸ í”¼ì²˜)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Ensemble Model (Soft Voting)"
      ],
      "metadata": {
        "id": "lLTApm3IHZk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ê° ëª¨ë¸ë³„ ë°ì´í„° ì¤€ë¹„ ë° ì˜ˆì¸¡\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ”® ì˜ˆì¸¡\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. RF ì˜ˆì¸¡ (í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ + Feature Selection)\n",
        "X_test_fe = create_features(X_test)\n",
        "X_test_rf = X_test_fe[rf_top_features]\n",
        "rf_pred = rf_model.predict(X_test_rf)\n",
        "rf_proba = rf_model.predict_proba(X_test_rf)\n",
        "print(f\"âœ… RF ì˜ˆì¸¡ ì™„ë£Œ\")\n",
        "\n",
        "# 2. XGBoost ì˜ˆì¸¡ (ì›ë³¸ ë°ì´í„°)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "xgb_proba = xgb_model.predict_proba(X_test)\n",
        "print(f\"âœ… XGBoost ì˜ˆì¸¡ ì™„ë£Œ\")\n",
        "\n",
        "# 3. FT Transformer ì˜ˆì¸¡ (ì›ë³¸ ë°ì´í„° + ìŠ¤ì¼€ì¼ë§)\n",
        "X_test_scaled = ft_scaler.transform(X_test)\n",
        "X_test_t = torch.FloatTensor(X_test_scaled).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    ft_logits = ft_model(X_test_t)\n",
        "    ft_pred = torch.argmax(ft_logits, dim=1).cpu().numpy()\n",
        "    ft_proba = torch.softmax(ft_logits, dim=1).cpu().numpy()\n",
        "print(f\"âœ… FT Transformer ì˜ˆì¸¡ ì™„ë£Œ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItTqLW4WYtH",
        "outputId": "8136de46-325b-4ea4-9c1f-cafffe1b701c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ”® ì˜ˆì¸¡\n",
            "============================================================\n",
            "âœ… RF ì˜ˆì¸¡ ì™„ë£Œ\n",
            "âœ… XGBoost ì˜ˆì¸¡ ì™„ë£Œ\n",
            "âœ… FT Transformer ì˜ˆì¸¡ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. ì•™ìƒë¸” ëª¨ë¸"
      ],
      "metadata": {
        "id": "XWxcfzYZWa91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ì•™ìƒë¸” (Soft Voting)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ† ì•™ìƒë¸” (Soft Voting)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ê°€ì¤‘ì¹˜ ì„¤ì • (ì¡°ì • ê°€ëŠ¥)\n",
        "weights = [0.3, 0.35, 0.35]  # RF, XGB, FT\n",
        "print(f\"ê°€ì¤‘ì¹˜: RF={weights[0]}, XGB={weights[1]}, FT={weights[2]}\")\n",
        "\n",
        "ensemble_proba = weights[0] * rf_proba + weights[1] * xgb_proba + weights[2] * ft_proba\n",
        "ensemble_pred = np.argmax(ensemble_proba, axis=1)\n",
        "\n",
        "# =============================================================================\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Random Forest  - Acc: {accuracy_score(y_test, rf_pred):.4f}, F1: {f1_score(y_test, rf_pred, average='macro'):.4f}\")\n",
        "print(f\"XGBoost        - Acc: {accuracy_score(y_test, xgb_pred):.4f}, F1: {f1_score(y_test, xgb_pred, average='macro'):.4f}\")\n",
        "print(f\"FT Transformer - Acc: {accuracy_score(y_test, ft_pred):.4f}, F1: {f1_score(y_test, ft_pred, average='macro'):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¯ ì•™ìƒë¸” ì„±ëŠ¥\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, ensemble_pred):.4f}\")\n",
        "print(f\"F1 Score (macro): {f1_score(y_test, ensemble_pred, average='macro'):.4f}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ Classification Report (ì•™ìƒë¸”):\")\n",
        "print(classification_report(y_test, ensemble_pred, target_names=['Bad', 'Standard', 'Good']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlGrqI6cWdmm",
        "outputId": "9f70fe3a-cf35-44ad-f6c8-fe6d1bc4c048"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ† ì•™ìƒë¸” (Soft Voting)\n",
            "============================================================\n",
            "ê°€ì¤‘ì¹˜: RF=0.3, XGB=0.35, FT=0.35\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥\n",
            "============================================================\n",
            "Random Forest  - Acc: 0.7967, F1: 0.7850\n",
            "XGBoost        - Acc: 0.8296, F1: 0.8239\n",
            "FT Transformer - Acc: 0.7347, F1: 0.7179\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ ì•™ìƒë¸” ì„±ëŠ¥\n",
            "============================================================\n",
            "Accuracy: 0.8084\n",
            "F1 Score (macro): 0.7997\n",
            "\n",
            "ğŸ“‹ Classification Report (ì•™ìƒë¸”):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.80      0.79      0.79      2749\n",
            "    Standard       0.83      0.82      0.83      5150\n",
            "        Good       0.75      0.81      0.78      1771\n",
            "\n",
            "    accuracy                           0.81      9670\n",
            "   macro avg       0.80      0.80      0.80      9670\n",
            "weighted avg       0.81      0.81      0.81      9670\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ë¹„êµ í…Œì´ë¸”\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š ìµœì¢… ê²°ê³¼ ë¹„êµ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'XGBoost', 'FT Transformer', 'ğŸ† Ensemble'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, rf_pred),\n",
        "        accuracy_score(y_test, xgb_pred),\n",
        "        accuracy_score(y_test, ft_pred),\n",
        "        accuracy_score(y_test, ensemble_pred)\n",
        "    ],\n",
        "    'F1 (macro)': [\n",
        "        f1_score(y_test, rf_pred, average='macro'),\n",
        "        f1_score(y_test, xgb_pred, average='macro'),\n",
        "        f1_score(y_test, ft_pred, average='macro'),\n",
        "        f1_score(y_test, ensemble_pred, average='macro')\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr2EWBpVWfHC",
        "outputId": "44c6064e-e81f-4bc9-cfe4-56c530cf97a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ“Š ìµœì¢… ê²°ê³¼ ë¹„êµ\n",
            "============================================================\n",
            "         Model  Accuracy  F1 (macro)\n",
            " Random Forest  0.796691    0.785042\n",
            "       XGBoost  0.829576    0.823887\n",
            "FT Transformer  0.734747    0.717948\n",
            "    ğŸ† Ensemble  0.808376    0.799707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. ì•™ìƒë¸” ëª¨ë¸ ê°€ì¤‘ì¹˜ íŠœë‹"
      ],
      "metadata": {
        "id": "6kjXI098WRNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ”§ ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_f1 = 0\n",
        "best_weights = None\n",
        "\n",
        "for w1 in np.arange(0.1, 0.6, 0.1):\n",
        "    for w2 in np.arange(0.1, 0.6, 0.1):\n",
        "        w3 = 1 - w1 - w2\n",
        "        if w3 < 0.1:\n",
        "            continue\n",
        "\n",
        "        ensemble_proba_temp = w1 * rf_proba + w2 * xgb_proba + w3 * ft_proba\n",
        "        ensemble_pred_temp = np.argmax(ensemble_proba_temp, axis=1)\n",
        "        f1_temp = f1_score(y_test, ensemble_pred_temp, average='macro')\n",
        "\n",
        "        if f1_temp > best_f1:\n",
        "            best_f1 = f1_temp\n",
        "            best_weights = (w1, w2, w3)\n",
        "\n",
        "print(f\"âœ… ìµœì  ê°€ì¤‘ì¹˜: RF={best_weights[0]:.1f}, XGB={best_weights[1]:.1f}, FT={best_weights[2]:.1f}\")\n",
        "print(f\"âœ… ìµœì  F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "# ìµœì  ê°€ì¤‘ì¹˜ë¡œ ìµœì¢… ì˜ˆì¸¡\n",
        "final_proba = best_weights[0] * rf_proba + best_weights[1] * xgb_proba + best_weights[2] * ft_proba\n",
        "final_pred = np.argmax(final_proba, axis=1)\n",
        "\n",
        "print(f\"\\nğŸ¯ ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” ì„±ëŠ¥:\")\n",
        "print(f\"   Accuracy: {accuracy_score(y_test, final_pred):.4f}\")\n",
        "print(f\"   F1 Score (macro): {f1_score(y_test, final_pred, average='macro'):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9j_c6KSWOXR",
        "outputId": "fe04bf7d-b1b9-4948-80ba-e7e25e14e91b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ”§ ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰\n",
            "============================================================\n",
            "âœ… ìµœì  ê°€ì¤‘ì¹˜: RF=0.3, XGB=0.5, FT=0.2\n",
            "âœ… ìµœì  F1 Score: 0.8131\n",
            "\n",
            "ğŸ¯ ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” ì„±ëŠ¥:\n",
            "   Accuracy: 0.8199\n",
            "   F1 Score (macro): 0.8131\n"
          ]
        }
      ]
    }
  ]
}
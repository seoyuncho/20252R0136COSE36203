{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b0c9836a6f548348096e0e1f2389321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a90e720b94b44ecba53a3809fb9cb87c",
              "IPY_MODEL_c763393b0e814f78a81642f975374ee1",
              "IPY_MODEL_b8804fb9088e43139696a1e49b23b48f"
            ],
            "layout": "IPY_MODEL_c74c8c904b22469a972d71fabff1b986"
          }
        },
        "a90e720b94b44ecba53a3809fb9cb87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7348462365d24a89825b79562691aa2f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7567a1f76f2e463ab2a425819942221f",
            "value": "Best‚Äátrial:‚Äá0.‚ÄáBest‚Äávalue:‚Äá0.698914:‚Äá100%"
          }
        },
        "c763393b0e814f78a81642f975374ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c810d9db064c1a86d61c040eb40a7e",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e47eef56dfbf4c51804881e396d62f4c",
            "value": 15
          }
        },
        "b8804fb9088e43139696a1e49b23b48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f4f40f639a49b3b3e1547b513ab6d3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab59ba6b78644f86a9e38daeca8e5308",
            "value": "‚Äá15/15‚Äá[16:29&lt;00:00,‚Äá74.84s/it]"
          }
        },
        "c74c8c904b22469a972d71fabff1b986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7348462365d24a89825b79562691aa2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7567a1f76f2e463ab2a425819942221f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c810d9db064c1a86d61c040eb40a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47eef56dfbf4c51804881e396d62f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5f4f40f639a49b3b3e1547b513ab6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab59ba6b78644f86a9e38daeca8e5308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å Ïó∞Í≤∞\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install optuna -q\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7RoBxysPPwt",
        "outputId": "b3adf05b-cfae-456c-dc6f-b12ba3edd521"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú"
      ],
      "metadata": {
        "id": "67__hw-UPLBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oTwS-AbNeOy",
        "outputId": "5adacf58-55b6-4f22-d35d-2a1015f913ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
            "============================================================\n",
            "‚úÖ Train+Val: (87026, 45), Test: (9670, 45)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "LOAD_PATH = '/content/drive/MyDrive/preprocessed_data.pkl'\n",
        "\n",
        "with open(LOAD_PATH, 'rb') as f:\n",
        "    data_dict = pickle.load(f)\n",
        "\n",
        "X_train = data_dict['X_train_clf']\n",
        "X_val = data_dict['X_val_clf']\n",
        "X_test = data_dict['X_test_clf']\n",
        "y_train = data_dict['y_train_clf']\n",
        "y_val = data_dict['y_val_clf']\n",
        "y_test = data_dict['y_test_clf']\n",
        "\n",
        "# Train + Val Ìï©ÏπòÍ∏∞\n",
        "X_train_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
        "y_train_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
        "\n",
        "print(f\"‚úÖ Train+Val: {X_train_full.shape}, Test: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Ïä§ÏºÄÏùºÎßÅ\n",
        "# =============================================================================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8MaOn4nrPmJG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GPU ÏÑ§Ï†ï\n",
        "# =============================================================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "389X-qHXPnXw",
        "outputId": "5c398bde-fb0a-42b1-d0be-d3bc2e019883"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ft-Transformer: Í∏∞Î≥∏"
      ],
      "metadata": {
        "id": "epECKnt1Pel5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Ft-Transformer Ï†ïÏùò"
      ],
      "metadata": {
        "id": "h7pF1iqZQ4KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, embed_dim=64, num_heads=4,\n",
        "                 num_layers=3, ff_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.feature_embedding = nn.Linear(1, embed_dim)\n",
        "        self.input_dim = input_dim\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, input_dim + 1, embed_dim))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(ff_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.feature_embedding(x)\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        x = x + self.pos_embedding\n",
        "        x = self.transformer(x)\n",
        "        cls_output = x[:, 0]\n",
        "        cls_output = self.norm(cls_output)\n",
        "        output = self.fc(cls_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "FfsDn-fSRAtX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ÌïôÏäµ Ìï®Ïàò\n",
        "# =============================================================================\n",
        "def train_and_evaluate(params, X_tr, y_tr, X_val, y_val, epochs=30, verbose=False):\n",
        "    \"\"\"Î™®Îç∏ ÌïôÏäµ Î∞è ÌèâÍ∞Ä\"\"\"\n",
        "\n",
        "    X_tr_t = torch.FloatTensor(X_tr).to(device)\n",
        "    y_tr_t = torch.LongTensor(y_tr).to(device)\n",
        "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
        "    y_val_t = torch.LongTensor(y_val).to(device)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_tr_t, y_tr_t), batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "    model = FTTransformer(\n",
        "        input_dim=X_tr.shape[1],\n",
        "        num_classes=3,\n",
        "        embed_dim=params['embed_dim'],\n",
        "        num_heads=params['num_heads'],\n",
        "        num_layers=params['num_layers'],\n",
        "        ff_dim=params['ff_dim'],\n",
        "        dropout=params['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=params.get('label_smoothing', 0.0))\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    best_val_acc = 0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val_t)\n",
        "            val_pred = torch.argmax(val_outputs, dim=1)\n",
        "            val_acc = (val_pred == y_val_t).float().mean().item()\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            print(f\"   Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= 5:\n",
        "                if verbose:\n",
        "                    print(f\"   Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, best_val_acc"
      ],
      "metadata": {
        "id": "oZ2y6puCQ91u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Ft-Transformer ÌïôÏäµ Î∞è ÌèâÍ∞Ä"
      ],
      "metadata": {
        "id": "hnPNwzQ3Q72m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ü§ñ FT Transformer (Í∏∞Î≥∏ Î≤ÑÏ†Ñ)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "base_params = {\n",
        "    'embed_dim': 64,\n",
        "    'num_heads': 4,\n",
        "    'num_layers': 3,\n",
        "    'ff_dim': 128,\n",
        "    'dropout': 0.1,\n",
        "    'lr': 1e-3,\n",
        "    'weight_decay': 1e-4,\n",
        "    'batch_size': 1024,\n",
        "    'label_smoothing': 0.0\n",
        "}\n",
        "\n",
        "base_model, _ = train_and_evaluate(\n",
        "    base_params,\n",
        "    X_train_scaled, y_train.values,\n",
        "    X_test_scaled, y_test.values,\n",
        "    epochs=30, verbose=True\n",
        ")\n",
        "\n",
        "X_test_t = torch.FloatTensor(X_test_scaled).to(device)\n",
        "base_model.eval()\n",
        "with torch.no_grad():\n",
        "    base_pred = torch.argmax(base_model(X_test_t), dim=1).cpu().numpy()\n",
        "\n",
        "base_acc = accuracy_score(y_test, base_pred)\n",
        "base_f1 = f1_score(y_test, base_pred, average='macro')\n",
        "\n",
        "print(f\"\\nAccuracy: {base_acc:.4f}\")\n",
        "print(f\"F1 Score (macro): {base_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2uKi-uTRHNB",
        "outputId": "2ffaddf9-34eb-46f8-c60b-aed574a8a348"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ü§ñ FT Transformer (Í∏∞Î≥∏ Î≤ÑÏ†Ñ)\n",
            "============================================================\n",
            "   Epoch 10: Val Acc = 0.7030\n",
            "   Epoch 20: Val Acc = 0.7058\n",
            "   Early stopping at epoch 24\n",
            "\n",
            "Accuracy: 0.7073\n",
            "F1 Score (macro): 0.6818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Ft-Transformer: ÏµúÏ†ÅÌôî"
      ],
      "metadata": {
        "id": "7tLtPaQ1Ompd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Optuna ÏµúÏ†ÅÌôî"
      ],
      "metadata": {
        "id": "cSrzRbANR-cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ü§ñ FT Transformer (Optuna ÏµúÏ†ÅÌôî)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def objective_ft(trial):\n",
        "    params = {\n",
        "        'embed_dim': trial.suggest_categorical('embed_dim', [32, 64]),\n",
        "        'num_heads': trial.suggest_categorical('num_heads', [4, 8]),\n",
        "        'num_layers': trial.suggest_int('num_layers', 2, 4),\n",
        "        'ff_dim': trial.suggest_categorical('ff_dim', [64, 128]),\n",
        "        'dropout': trial.suggest_float('dropout', 0.1, 0.3),\n",
        "        'lr': trial.suggest_float('lr', 1e-4, 1e-3, log=True),\n",
        "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [512, 1024]),\n",
        "        'label_smoothing': trial.suggest_float('label_smoothing', 0.0, 0.15)\n",
        "    }\n",
        "\n",
        "    if params['embed_dim'] % params['num_heads'] != 0:\n",
        "        return 0.0\n",
        "\n",
        "    X_tr, X_val_split, y_tr, y_val_split = train_test_split(\n",
        "        X_train_scaled, y_train.values,\n",
        "        test_size=0.2, random_state=42, stratify=y_train\n",
        "    )\n",
        "\n",
        "    _, best_acc = train_and_evaluate(params, X_tr, y_tr, X_val_split, y_val_split, epochs=20)\n",
        "    return best_acc\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "study_ft = optuna.create_study(direction='maximize')\n",
        "study_ft.optimize(objective_ft, n_trials=15, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\n‚úÖ ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞: {study_ft.best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "8b0c9836a6f548348096e0e1f2389321",
            "a90e720b94b44ecba53a3809fb9cb87c",
            "c763393b0e814f78a81642f975374ee1",
            "b8804fb9088e43139696a1e49b23b48f",
            "c74c8c904b22469a972d71fabff1b986",
            "7348462365d24a89825b79562691aa2f",
            "7567a1f76f2e463ab2a425819942221f",
            "b4c810d9db064c1a86d61c040eb40a7e",
            "e47eef56dfbf4c51804881e396d62f4c",
            "e5f4f40f639a49b3b3e1547b513ab6d3",
            "ab59ba6b78644f86a9e38daeca8e5308"
          ]
        },
        "id": "Ecs5EGxAO7aV",
        "outputId": "ddc6280c-24c5-492c-d397-19a33d5f020e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ü§ñ FT Transformer (Optuna ÏµúÏ†ÅÌôî)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b0c9836a6f548348096e0e1f2389321"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞: {'embed_dim': 64, 'num_heads': 4, 'num_layers': 4, 'ff_dim': 64, 'dropout': 0.10866552753221051, 'lr': 0.0009971511157826653, 'weight_decay': 2.5112890083621004e-05, 'batch_size': 1024, 'label_smoothing': 0.11744100649707297}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Ft-Transformer ÌïôÏäµ Î∞è ÏÑ±Îä• ÌèâÍ∞Ä"
      ],
      "metadata": {
        "id": "KDPWPGprOs5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_model, _ = train_and_evaluate(\n",
        "    study_ft.best_params,\n",
        "    X_train_scaled, y_train.values,\n",
        "    X_test_scaled, y_test.values,\n",
        "    epochs=50, verbose=True\n",
        ")\n",
        "\n",
        "opt_model.eval()\n",
        "with torch.no_grad():\n",
        "    opt_pred = torch.argmax(opt_model(X_test_t), dim=1).cpu().numpy()\n",
        "\n",
        "opt_acc = accuracy_score(y_test, opt_pred)\n",
        "opt_f1 = f1_score(y_test, opt_pred, average='macro')\n",
        "\n",
        "print(f\"\\nAccuracy: {opt_acc:.4f}\")\n",
        "print(f\"F1 Score (macro): {opt_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRb6VLFRSTVG",
        "outputId": "49cd912c-ad23-43c5-ab1d-6b54431455ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 10: Val Acc = 0.7030\n",
            "   Epoch 20: Val Acc = 0.7125\n",
            "   Epoch 30: Val Acc = 0.7270\n",
            "   Epoch 40: Val Acc = 0.7310\n",
            "   Epoch 50: Val Acc = 0.7347\n",
            "\n",
            "Accuracy: 0.7347\n",
            "F1 Score (macro): 0.7179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ÎπÑÍµê Í≤∞Í≥º\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Í∏∞Î≥∏ vs ÏµúÏ†ÅÌôî ÎπÑÍµê\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['FT Transformer (Í∏∞Î≥∏)', 'FT Transformer (Optuna)'],\n",
        "    'Accuracy': [base_acc, opt_acc],\n",
        "    'F1 (macro)': [base_f1, opt_f1]\n",
        "})\n",
        "print(comparison.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PuJyJMNOzuQ",
        "outputId": "4e28b845-b9a6-497d-dc36-34b38affc48d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä Í∏∞Î≥∏ vs ÏµúÏ†ÅÌôî ÎπÑÍµê\n",
            "============================================================\n",
            "                  Model  Accuracy  F1 (macro)\n",
            "    FT Transformer (Í∏∞Î≥∏)  0.707342    0.681775\n",
            "FT Transformer (Optuna)  0.734747    0.717948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = '/content/drive/MyDrive/best_ft_model.pkl'\n",
        "\n",
        "best_model = opt_model if opt_f1 > base_f1 else base_model\n",
        "best_params = study_ft.best_params if opt_f1 > base_f1 else base_params\n",
        "\n",
        "save_dict = {\n",
        "    'model_state': best_model.state_dict(),\n",
        "    'best_params': best_params,\n",
        "    'scaler': scaler,\n",
        "    'input_dim': X_train_full.shape[1],\n",
        "    'feature_columns': X_train_full.columns.tolist()\n",
        "}\n",
        "\n",
        "with open(SAVE_PATH, 'wb') as f:\n",
        "    pickle.dump(save_dict, f)\n",
        "\n",
        "print(f\"\\n‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBo3vjrqO1Pw",
        "outputId": "6d16e760-3b5f-4f0d-d2db-41fa0cb7a148"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: /content/drive/MyDrive/best_ft_model.pkl\n"
          ]
        }
      ]
    }
  ]
}